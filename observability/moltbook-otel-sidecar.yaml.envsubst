---
# OpenTelemetryCollector for moltbook namespace (sidecar mode)
# Auto-injected into pods with annotation: sidecar.opentelemetry.io/inject: "moltbook-sidecar"
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: moltbook-sidecar
  namespace: moltbook
spec:
  mode: sidecar

  config: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 127.0.0.1:4317
          http:
            endpoint: 127.0.0.1:4318

    processors:
      # Batch processor for better performance
      batch:
        timeout: 10s
        send_batch_size: 1024

      # Memory limiter to prevent OOM
      memory_limiter:
        check_interval: 1s
        limit_mib: 256
        spike_limit_mib: 64

      # Probabilistic sampler to reduce trace volume (10% sampling)
      probabilistic_sampler:
        sampling_percentage: 10.0

      # Resource processor to add namespace info
      resource:
        attributes:
          - key: service.namespace
            value: moltbook
            action: upsert
          - key: k8s.namespace.name
            value: moltbook
            action: upsert
          - key: deployment.environment
            value: production
            action: upsert
          - key: mlflow.experimentName
            value: OpenClaw
            action: upsert
          - key: mlflow.projectName
            value: OpenClaw
            action: upsert

    exporters:
      # Export to MLflow OTLP endpoint (path /v1/traces is auto-appended)
      otlphttp:
        # UPDATE TO MATCH YOUR MLFLOW ENDPOINT - Do not append /v1/traces
        endpoint: http://mlflow-service.mlflow.svc.cluster.local:5000
        headers:
          x-mlflow-experiment-id: "4"
          x-mlflow-workspace: "moltbook"
        tls:
          insecure: true

      # Debug exporter for troubleshooting
      debug:
        verbosity: normal

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, probabilistic_sampler, resource, batch]
          exporters: [otlphttp, debug]

  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 256Mi
      cpu: 200m
